{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOdaY+VKQZni30cqQYJd8QE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Klnishant/ANNImplementation/blob/main/textProcessingUsingNLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TeJrZx1JttT"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer,WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"\"\"\n",
        "Natural language processing (NLP) is a field of artificial intelligence that focuses on the interaction\n",
        "between computers and humans through natural language. The ultimate goal of NLP is to read, decipher,\n",
        "understand, and make sense of human language in a way that is both valuable and meaningful.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Xiey7UCpKxoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NH0yyBClLJm8",
        "outputId": "1fd88b07-c24b-4379-b8a0-75a500168446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentensces = sent_tokenize(sample_text)\n",
        "words = [word_tokenize(sentence) for sentence in sentensces ]\n",
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbF0Z01vLb8O",
        "outputId": "8c72ed12-7897-46e8-a437-e575be79f963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Natural',\n",
              "  'language',\n",
              "  'processing',\n",
              "  '(',\n",
              "  'NLP',\n",
              "  ')',\n",
              "  'is',\n",
              "  'a',\n",
              "  'field',\n",
              "  'of',\n",
              "  'artificial',\n",
              "  'intelligence',\n",
              "  'that',\n",
              "  'focuses',\n",
              "  'on',\n",
              "  'the',\n",
              "  'interaction',\n",
              "  'between',\n",
              "  'computers',\n",
              "  'and',\n",
              "  'humans',\n",
              "  'through',\n",
              "  'natural',\n",
              "  'language',\n",
              "  '.'],\n",
              " ['The',\n",
              "  'ultimate',\n",
              "  'goal',\n",
              "  'of',\n",
              "  'NLP',\n",
              "  'is',\n",
              "  'to',\n",
              "  'read',\n",
              "  ',',\n",
              "  'decipher',\n",
              "  ',',\n",
              "  'understand',\n",
              "  ',',\n",
              "  'and',\n",
              "  'make',\n",
              "  'sense',\n",
              "  'of',\n",
              "  'human',\n",
              "  'language',\n",
              "  'in',\n",
              "  'a',\n",
              "  'way',\n",
              "  'that',\n",
              "  'is',\n",
              "  'both',\n",
              "  'valuable',\n",
              "  'and',\n",
              "  'meaningful',\n",
              "  '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_words = [[re.sub(r'[^a-zA-Z0-9]', '', word.lower()) for word in sentence] for sentence in words]"
      ],
      "metadata": {
        "id": "LLDZa_ETMABy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FC0eUqNIMIMa",
        "outputId": "23c02693-8ada-4468-a55f-c176daeecd69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['natural',\n",
              "  'language',\n",
              "  'processing',\n",
              "  '',\n",
              "  'nlp',\n",
              "  '',\n",
              "  'is',\n",
              "  'a',\n",
              "  'field',\n",
              "  'of',\n",
              "  'artificial',\n",
              "  'intelligence',\n",
              "  'that',\n",
              "  'focuses',\n",
              "  'on',\n",
              "  'the',\n",
              "  'interaction',\n",
              "  'between',\n",
              "  'computers',\n",
              "  'and',\n",
              "  'humans',\n",
              "  'through',\n",
              "  'natural',\n",
              "  'language',\n",
              "  ''],\n",
              " ['the',\n",
              "  'ultimate',\n",
              "  'goal',\n",
              "  'of',\n",
              "  'nlp',\n",
              "  'is',\n",
              "  'to',\n",
              "  'read',\n",
              "  '',\n",
              "  'decipher',\n",
              "  '',\n",
              "  'understand',\n",
              "  '',\n",
              "  'and',\n",
              "  'make',\n",
              "  'sense',\n",
              "  'of',\n",
              "  'human',\n",
              "  'language',\n",
              "  'in',\n",
              "  'a',\n",
              "  'way',\n",
              "  'that',\n",
              "  'is',\n",
              "  'both',\n",
              "  'valuable',\n",
              "  'and',\n",
              "  'meaningful',\n",
              "  '']]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "filterd_words = [[word for word in sentensces if word not in stop_words] for sentensces in sentensces]"
      ],
      "metadata": {
        "id": "pnNe5fvHMLFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "lammatizer = WordNetLemmatizer()\n",
        "stemm_words = [[stemmer.stem(word) for word in sentences] for sentences in cleaned_words]\n",
        "lammatizer_words = [[lammatizer.lemmatize(word) for word in sentence] for sentence in cleaned_words]"
      ],
      "metadata": {
        "id": "Fsr7FnqpM4X_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lammatizer_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dtmYSHvOAbp",
        "outputId": "b9aeccf7-86ae-4843-8e26-a6897d214622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['natural',\n",
              "  'language',\n",
              "  'processing',\n",
              "  '',\n",
              "  'nlp',\n",
              "  '',\n",
              "  'is',\n",
              "  'a',\n",
              "  'field',\n",
              "  'of',\n",
              "  'artificial',\n",
              "  'intelligence',\n",
              "  'that',\n",
              "  'focus',\n",
              "  'on',\n",
              "  'the',\n",
              "  'interaction',\n",
              "  'between',\n",
              "  'computer',\n",
              "  'and',\n",
              "  'human',\n",
              "  'through',\n",
              "  'natural',\n",
              "  'language',\n",
              "  ''],\n",
              " ['the',\n",
              "  'ultimate',\n",
              "  'goal',\n",
              "  'of',\n",
              "  'nlp',\n",
              "  'is',\n",
              "  'to',\n",
              "  'read',\n",
              "  '',\n",
              "  'decipher',\n",
              "  '',\n",
              "  'understand',\n",
              "  '',\n",
              "  'and',\n",
              "  'make',\n",
              "  'sense',\n",
              "  'of',\n",
              "  'human',\n",
              "  'language',\n",
              "  'in',\n",
              "  'a',\n",
              "  'way',\n",
              "  'that',\n",
              "  'is',\n",
              "  'both',\n",
              "  'valuable',\n",
              "  'and',\n",
              "  'meaningful',\n",
              "  '']]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"original sentence\")\n",
        "for sentensces in sentensces:\n",
        "    print(sentensces)\n",
        "\n",
        "print(\"lamatized sentence\")\n",
        "for sentensces in lammatizer_words:\n",
        "  print(' '.join(sentensces))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMGZyJeUOEua",
        "outputId": "c09bb5c0-5407-4873-83eb-abe5120f0e72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original sentence\n",
            "\n",
            "Natural language processing (NLP) is a field of artificial intelligence that focuses on the interaction\n",
            "between computers and humans through natural language.\n",
            "The ultimate goal of NLP is to read, decipher,\n",
            "understand, and make sense of human language in a way that is both valuable and meaningful.\n",
            "lamatized sentence\n",
            "natural language processing  nlp  is a field of artificial intelligence that focus on the interaction between computer and human through natural language \n",
            "the ultimate goal of nlp is to read  decipher  understand  and make sense of human language in a way that is both valuable and meaningful \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "axJDyigzO6z4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}