{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMY19uU2/5dIjjHCvbmxQWr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Klnishant/ANNImplementation/blob/main/NLTK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02-Pf2vAK5h7",
        "outputId": "6e637a88-b70c-4b01-a0d7-bef6bc75a949"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctm9wOPxK_Bv",
        "outputId": "d8ddb0ef-961d-4a27-fff1-f99036f4a8f4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"NLTK is a powerful tool for natural language processing. It can tokenize sentences and words. NLTK includes various NLP libraries for text analysis.\""
      ],
      "metadata": {
        "id": "O-BBMivRLujm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tokenization of text\")\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "sentences = sent_tokenize(text)\n",
        "words =word_tokenize(text)\n",
        "print(sentences)\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhC2sbCZL3Db",
        "outputId": "81d9af81-f028-4f3b-f825-7c789e921ad6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization of text\n",
            "['NLTK is a powerful tool for natural language processing.', 'It can tokenize sentences and words.', 'NLTK includes various NLP libraries for text analysis.']\n",
            "['NLTK', 'is', 'a', 'powerful', 'tool', 'for', 'natural', 'language', 'processing', '.', 'It', 'can', 'tokenize', 'sentences', 'and', 'words', '.', 'NLTK', 'includes', 'various', 'NLP', 'libraries', 'for', 'text', 'analysis', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag\n",
        "pos_tags = pos_tag(words)\n",
        "print(pos_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "In_Len1cMXwJ",
        "outputId": "bbb99dcf-dba9-4044-dce1-394de241d6c9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('NLTK', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('powerful', 'JJ'), ('tool', 'NN'), ('for', 'IN'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('.', '.'), ('It', 'PRP'), ('can', 'MD'), ('tokenize', 'VB'), ('sentences', 'NNS'), ('and', 'CC'), ('words', 'NNS'), ('.', '.'), ('NLTK', 'NNP'), ('includes', 'VBZ'), ('various', 'JJ'), ('NLP', 'NNP'), ('libraries', 'NNS'), ('for', 'IN'), ('text', 'JJ'), ('analysis', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmmed_words = [stemmer.stem(word) for word in words]\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "print(stemmmed_words)\n",
        "print(lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xJMII-wMsPB",
        "outputId": "7d395051-c593-494b-8000-d10e2859219f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['nltk', 'is', 'a', 'power', 'tool', 'for', 'natur', 'languag', 'process', '.', 'it', 'can', 'token', 'sentenc', 'and', 'word', '.', 'nltk', 'includ', 'variou', 'nlp', 'librari', 'for', 'text', 'analysi', '.']\n",
            "['NLTK', 'is', 'a', 'powerful', 'tool', 'for', 'natural', 'language', 'processing', '.', 'It', 'can', 'tokenize', 'sentence', 'and', 'word', '.', 'NLTK', 'includes', 'various', 'NLP', 'library', 'for', 'text', 'analysis', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filltered_words = [word for word in words if word.lower() not in stop_words]\n",
        "print(filltered_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IIAIzQ4NisS",
        "outputId": "4b31f437-f59a-4ebd-eea4-4e7a6229af6d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NLTK', 'powerful', 'tool', 'natural', 'language', 'processing', '.', 'tokenize', 'sentences', 'words', '.', 'NLTK', 'includes', 'various', 'NLP', 'libraries', 'text', 'analysis', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import FreqDist\n",
        "freq_dist = FreqDist(words)\n",
        "print(freq_dist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i41jSTiNOXnv",
        "outputId": "09b8b647-36b8-476b-b7d3-a06eceaf9912"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<FreqDist with 22 samples and 26 outcomes>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.text import Text\n",
        "text_object = Text(words)\n",
        "coonderance = text_object.concordance(\"NLTK\")\n",
        "similar_words = text_object.similar(\"tool\")\n",
        "print(coonderance)\n",
        "print(similar_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SEfqlLbOtr_",
        "outputId": "8ded5ac0-274a-458d-84c4-555295a018c1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 2 of 2 matches:\n",
            " NLTK is a powerful tool for natural langu\n",
            "t can tokenize sentences and words . NLTK includes various NLP libraries for t\n",
            "\n",
            "None\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFpJrq1DQcGS",
        "outputId": "614f31bb-58fa-47d6-85bc-9cf0dbf53eef"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "sentiment_scores = sia.polarity_scores(text)\n",
        "print(sentiment_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWIkE7XnPx7i",
        "outputId": "58064d17-a8d4-46dc-8fb4-24c23aa84f22"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'neg': 0.0, 'neu': 0.745, 'pos': 0.255, 'compound': 0.6705}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import ne_chunk\n",
        "ner_result = ne_chunk(pos_tags)\n",
        "print(ner_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aedglJPXQVD9",
        "outputId": "2177eb76-3efd-4c3d-a605-845b0c673d3a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (ORGANIZATION NLTK/NNP)\n",
            "  is/VBZ\n",
            "  a/DT\n",
            "  powerful/JJ\n",
            "  tool/NN\n",
            "  for/IN\n",
            "  natural/JJ\n",
            "  language/NN\n",
            "  processing/NN\n",
            "  ./.\n",
            "  It/PRP\n",
            "  can/MD\n",
            "  tokenize/VB\n",
            "  sentences/NNS\n",
            "  and/CC\n",
            "  words/NNS\n",
            "  ./.\n",
            "  (ORGANIZATION NLTK/NNP)\n",
            "  includes/VBZ\n",
            "  various/JJ\n",
            "  (ORGANIZATION NLP/NNP)\n",
            "  libraries/NNS\n",
            "  for/IN\n",
            "  text/JJ\n",
            "  analysis/NN\n",
            "  ./.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uSHFAz1SRJFL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}